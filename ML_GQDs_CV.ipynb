{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hazem-Abdelsalam/ML-QDs-electronic-properties/blob/main/ML_GQDs_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WrjPWmE_cc2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install & Setup"
      ],
      "metadata": {
        "id": "0WvZ5teUW7D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1A: Install, Import & Setup (Run once)\n",
        "import os\n",
        "\n",
        "# Install chemprop from GitHub if in Colab\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "    try:\n",
        "        import chemprop\n",
        "    except ImportError:\n",
        "        !git clone https://github.com/chemprop/chemprop.git && cd chemprop && pip install . && cd ..\n",
        "        !pip install rdkit-pypi --pre deepchem\n",
        "\n",
        "# Imports\n",
        "from pathlib import Path\n",
        "from lightning import pytorch as pl\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import re\n",
        "from typing import List\n",
        "from rdkit import RDLogger\n",
        "\n",
        "# Set seed for reproducibility\n",
        "pl.seed_everything(24, workers=True)\n",
        "\n",
        "# Disable RDKit warnings\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "print(\"‚úÖ Environment setup complete.\")"
      ],
      "metadata": {
        "id": "PafKW2ixpGbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload CSV & Preview Data"
      ],
      "metadata": {
        "id": "MD7j6opcpsVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1B: Upload CSV & Preview Data\n",
        "\n",
        "def upload_and_combine_csvs(\n",
        "    expected_base_names: List[str] = ['GQDs_SiCQDs_Data'],\n",
        "    smiles_columns: List[str] = ['SMILES'],\n",
        "    name_columns: List[str] = ['Name'],\n",
        "    target_columns: List[List[str]] = [['HOMO', 'LUMO']],\n",
        "    output_filename: str = 'combined_cleaned_results.csv'\n",
        ") -> pd.DataFrame:\n",
        "    print(\"üì§ Please upload your CSV file...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    def find_matching_file(base_name):\n",
        "        pattern = re.compile(fr'{re.escape(base_name)}(?:\\s*\\(\\d+\\))?\\.csv', re.IGNORECASE)\n",
        "        for filename in uploaded.keys():\n",
        "            if pattern.search(filename):\n",
        "                return filename\n",
        "        return None\n",
        "\n",
        "    dfs = []\n",
        "    for base_name, smi_col, name_col, tgt_cols in zip(expected_base_names, smiles_columns, name_columns, target_columns):\n",
        "        matched_file = find_matching_file(base_name)\n",
        "        if not matched_file:\n",
        "            available_files = \"\\n\".join(uploaded.keys())\n",
        "            raise FileNotFoundError(f\"No file matching '{base_name}' found.\\nAvailable files:\\n{available_files}\")\n",
        "        print(f\"\\nüìÅ Processing file: {matched_file}\")\n",
        "        try:\n",
        "            df = pd.read_csv(matched_file)\n",
        "\n",
        "            # Normalize column names\n",
        "            df = df.rename(columns={smi_col: 'smiles'})\n",
        "            if name_col in df.columns:\n",
        "                df = df.rename(columns={name_col: 'name'})\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Warning: 'Name' column not found. Generating generic names.\")\n",
        "                df['name'] = [f\"mol_{i}\" for i in range(len(df))]\n",
        "\n",
        "            for tgt_col in tgt_cols:\n",
        "                df = df.rename(columns={tgt_col: tgt_col.lower()})\n",
        "\n",
        "            required_cols = ['smiles', 'name'] + [col.lower() for col in tgt_cols]\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                missing = set(required_cols) - set(df.columns)\n",
        "                raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "            df = df[required_cols].dropna()\n",
        "            dfs.append(df)\n",
        "            print(f\"- Processed {len(df)} rows\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error processing {matched_file}: {e}\")\n",
        "\n",
        "    combined_df = pd.concat(dfs, ignore_index=True)\n",
        "    combined_df.to_csv(output_filename, index=False)\n",
        "    print(f\"\\nüíæ Saved combined data: {output_filename}\")\n",
        "    return combined_df\n",
        "\n",
        "# Run upload and data loading\n",
        "try:\n",
        "    df_input = upload_and_combine_csvs()\n",
        "    smis = df_input['smiles'].values\n",
        "    names = df_input['name'].values\n",
        "    ys_all = df_input[[ 'homo', 'lumo']].values\n",
        "    print(f\"\\n‚úÖ Success! Total molecules: {len(smis)}\")\n",
        "\n",
        "    # Preview first 5 entries: Name + targets (not SMILES)\n",
        "    print(\"\\nüìã First 5 entries (Name + Targets):\")\n",
        "    preview_df = df_input[['name',  'homo', 'lumo']].head(5)\n",
        "    display(preview_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to process file: {e}\")"
      ],
      "metadata": {
        "id": "zPcS32ACpR-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42NjPanC_cdA"
      },
      "source": [
        "# # Step 2: K-Fold Cross-Validation Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: K-Fold Training & Prediction (Core Model) ‚Äî EHOMO & ELUMO ONLY\n",
        "from sklearn.model_selection import KFold\n",
        "from chemprop import data, featurizers, models, nn\n",
        "import numpy as np\n",
        "\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to collect results across folds\n",
        "all_true, all_pred, all_smiles, all_names = [], [], [], []\n",
        "\n",
        "for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(smis)):\n",
        "    print(f\"\\n--- Fold {fold_idx + 1} / {k_folds} ---\")\n",
        "\n",
        "    # Split data using indices\n",
        "    smis_train_val = [smis[i] for i in train_val_idx]\n",
        "    names_train_val = [names[i] for i in train_val_idx]\n",
        "    ys_train_val = ys_all[train_val_idx]\n",
        "\n",
        "    smis_test = [smis[i] for i in test_idx]\n",
        "    names_test = [names[i] for i in test_idx]\n",
        "    ys_test = ys_all[test_idx]\n",
        "\n",
        "    # Create MoleculeDatapoint objects\n",
        "    all_data_train_val = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis_train_val, ys_train_val)]\n",
        "    all_data_test = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis_test, ys_test)]\n",
        "\n",
        "    # Inner split: train / validation\n",
        "    train_val_mols = [d.mol for d in all_data_train_val]\n",
        "    inner_kf = KFold(n_splits=5, shuffle=True)\n",
        "    train_inner_idx, val_inner_idx = next(inner_kf.split(train_val_mols))\n",
        "\n",
        "    train_data, val_data, _ = data.split_data_by_indices(\n",
        "        all_data_train_val, [train_inner_idx], [val_inner_idx], []\n",
        "    )\n",
        "    train_data = train_data[0]\n",
        "    val_data = val_data[0]\n",
        "    test_data = all_data_test\n",
        "\n",
        "    # Featurizer and Datasets\n",
        "    featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
        "    train_dset = data.MoleculeDataset(train_data, featurizer)\n",
        "    scaler = train_dset.normalize_targets()\n",
        "\n",
        "    val_dset = data.MoleculeDataset(val_data, featurizer)\n",
        "    val_dset.normalize_targets(scaler)\n",
        "\n",
        "    test_dset = data.MoleculeDataset(test_data, featurizer)\n",
        "    test_dset.normalize_targets(scaler)\n",
        "\n",
        "    # DataLoaders\n",
        "    num_workers = 4\n",
        "    train_loader = data.build_dataloader(train_dset, num_workers=num_workers, shuffle=True)\n",
        "    val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
        "    test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)\n",
        "\n",
        "    # Build MPNN Model ‚Äî ‚ö†Ô∏è n_tasks=2 for homo and lumo\n",
        "    mp = nn.BondMessagePassing()\n",
        "    agg = nn.MeanAggregation()\n",
        "    output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
        "    ffn = nn.RegressionFFN(output_transform=output_transform, n_tasks=2)  # ‚úÖ CHANGED FROM 3 TO 2\n",
        "    batch_norm = True\n",
        "    metric_list = [nn.metrics.RMSE(), nn.metrics.MAE(), nn.metrics.R2Score()]\n",
        "\n",
        "    mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
        "\n",
        "    # Trainer with checkpointing\n",
        "    checkpointing = ModelCheckpoint(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        save_last=True,\n",
        "        dirpath=\"checkpoints\",\n",
        "        filename=f\"fold_{fold_idx}_best\"\n",
        "    )\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        logger=False,\n",
        "        enable_checkpointing=True,\n",
        "        enable_progress_bar=True,\n",
        "        accelerator=\"auto\",\n",
        "        devices=1,\n",
        "        max_epochs=300,\n",
        "        callbacks=[checkpointing],\n",
        "        deterministic=True\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer.fit(mpnn, train_loader, val_loader)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_preds = trainer.predict(mpnn, test_loader)\n",
        "    preds = torch.cat([p for p in test_preds], dim=0).numpy()\n",
        "\n",
        "    # Store results for this fold\n",
        "    all_true.append(ys_test)\n",
        "    all_pred.append(preds)\n",
        "    all_smiles.extend([smis[i] for i in test_idx])\n",
        "    all_names.extend([names[i] for i in test_idx])\n",
        "\n",
        "# Combine results from all folds\n",
        "all_true = np.vstack(all_true)  # Shape: (N, 2)\n",
        "all_pred = np.vstack(all_pred)  # Shape: (N, 2)\n",
        "all_smiles = np.array(all_smiles)\n",
        "all_names = np.array(all_names)\n",
        "\n",
        "print(f\"\\n‚úÖ K-Fold completed. Total test predictions: {len(all_names)}\")"
      ],
      "metadata": {
        "id": "PkYkd2DPeBIr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj2G-R0L6mlf"
      },
      "source": [
        " # Step 3: Results & Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSRdz6kPWkdZ"
      },
      "outputs": [],
      "source": [
        "# Step 3: Results & Plotting ‚Äî EHOMO & ELUMO ONLY\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Create results DataFrame ‚Äî NO GAP\n",
        "results_df = pd.DataFrame({\n",
        "    'Name': all_names,\n",
        "    'True_homo': all_true[:, 0],\n",
        "    'True_lumo': all_true[:, 1],\n",
        "    'Pred_homo': all_pred[:, 0],\n",
        "    'Pred_lumo': all_pred[:, 1]\n",
        "})\n",
        "\n",
        "# Add error metrics for homo and lumo only\n",
        "for tgt in ['homo', 'lumo']:\n",
        "    results_df[f'Error_{tgt}'] = (results_df[f'True_{tgt}'] - results_df[f'Pred_{tgt}']).abs()\n",
        "    results_df[f'Signed_Error_{tgt}'] = results_df[f'True_{tgt}'] - results_df[f'Pred_{tgt}']\n",
        "    results_df[f'Pct_Error_{tgt}'] = (results_df[f'Error_{tgt}'] / (results_df[f'True_{tgt}'] + 1e-8)) * 100\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv('test_set_predictions.csv', index=False)\n",
        "print(\"‚úÖ Full results saved to 'test_set_predictions.csv'\")\n",
        "\n",
        "# UNIFORM BOLD FONT SETUP\n",
        "plt.rcParams.update({\n",
        "    'font.size': 14,\n",
        "    'font.weight': 'bold',\n",
        "    'axes.labelweight': 'bold',\n",
        "    'axes.titleweight': 'bold',\n",
        "    'legend.fontsize': 12,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'axes.titlesize': 14,\n",
        "    'figure.titlesize': 16\n",
        "})\n",
        "\n",
        "# Plotting: True vs Predicted ‚Äî ONLY 2 TARGETS\n",
        "targets = ['homo', 'lumo']\n",
        "colors = ['green', 'orange']\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # Changed from 1x3 to 1x2\n",
        "\n",
        "for i, target in enumerate(targets):\n",
        "    t = results_df[f'True_{target}']\n",
        "    p = results_df[f'Pred_{target}']\n",
        "    r2 = r2_score(t, p)\n",
        "    mae = mean_absolute_error(t, p)\n",
        "    rmse = np.sqrt(mean_squared_error(t, p))\n",
        "\n",
        "    axes[i].scatter(t, p, alpha=0.7, edgecolors='w', s=60, color=colors[i])\n",
        "    axes[i].plot([t.min(), t.max()], [t.min(), t.max()], 'r--', label='Ideal')\n",
        "    axes[i].text(0.05, 0.85, f'R¬≤ = {r2:.3f}\\nMAE = {mae:.3f}\\nRMSE = {rmse:.3f}',\n",
        "                 transform=axes[i].transAxes, fontsize=12, weight='bold',\n",
        "                 bbox=dict(facecolor='white', alpha=0.8))\n",
        "    axes[i].set_xlabel('True Values (eV)')\n",
        "    axes[i].set_ylabel('Predicted Values (eV)')\n",
        "    axes[i].set_title(f'{target.upper()}: True vs Predicted')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Error Distribution Plots ‚Äî ONLY 2 TARGETS\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "for i, (target, color) in enumerate(zip(targets, colors)):\n",
        "    errors = results_df[f'Signed_Error_{target}']\n",
        "    axes[i].hist(errors, bins=15, alpha=0.7, color=color, edgecolor='black')\n",
        "    axes[i].axvline(x=errors.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                    label=f'Mean: {errors.mean():.4f}')\n",
        "    axes[i].axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
        "    axes[i].set_xlabel('Prediction Error (eV)')\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "    axes[i].set_title(f'{target.upper()} Error Distribution')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Prediction Error Distributions', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final metrics summary ‚Äî ONLY 2 TARGETS\n",
        "print(\"\\nüìä Performance Summary:\")\n",
        "for target in ['homo', 'lumo']:\n",
        "    t = results_df[f'True_{target}']\n",
        "    p = results_df[f'Pred_{target}']\n",
        "    r2 = r2_score(t, p)\n",
        "    mae = mean_absolute_error(t, p)\n",
        "    rmse = np.sqrt(mean_squared_error(t, p))\n",
        "    print(f\"{target.upper()}: R¬≤={r2:.4f}, MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
        "\n",
        "# Create a table for 10 representative quantum dots ‚Äî NO GAP\n",
        "print(\"\\nüìä Table of True vs Predicted Values for Representative Quantum Dots:\")\n",
        "table_data = []\n",
        "\n",
        "# Select 10 random rows\n",
        "representative_samples = results_df.sample(n=10, random_state=42)\n",
        "\n",
        "for _, row in representative_samples.iterrows():\n",
        "    name = row['Name']\n",
        "    true_homo, true_lumo = row['True_homo'], row['True_lumo']\n",
        "    pred_homo, pred_lumo = row['Pred_homo'], row['Pred_lumo']\n",
        "    error_homo = abs(true_homo - pred_homo)\n",
        "    error_lumo = abs(true_lumo - pred_lumo)\n",
        "\n",
        "    table_data.append([\n",
        "        name,\n",
        "        true_homo, true_lumo,\n",
        "        pred_homo, pred_lumo,\n",
        "        error_homo, error_lumo\n",
        "    ])\n",
        "\n",
        "# DataFrame with NO GAP columns\n",
        "table_columns = [\n",
        "    \"Name\",\n",
        "    \"True EHOMO\", \"True ELUMO\",\n",
        "    \"Pred EHOMO\", \"Pred ELUMO\",\n",
        "    \"Error EHOMO\", \"Error ELUMO\"\n",
        "]\n",
        "\n",
        "table_df = pd.DataFrame(table_data, columns=table_columns)\n",
        "print(table_df.to_string(index=False))\n",
        "\n",
        "# Save table\n",
        "table_df.to_csv(\"representative_predictions_table.csv\", index=False)\n",
        "print(\"\\n‚úÖ Table saved to 'representative_predictions_table.csv'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "chemprop_pr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}